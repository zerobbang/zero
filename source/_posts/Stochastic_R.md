---
title: Stochastic Gradient Descent
date : "2022-03-29"
categories:
- [Study]
---

- Stochastic Gradient Descent?
    
     확률적 경사 하강법은 간단히 말해서 데이터들 중 무작위로 하나의 샘플 데이터의 경사를 계산하는 법이다.
    즉, 학습할 때 하나의 샘플 데이터를 다루기 때문에 한번에 다뤄야 할 데이터 수가 상대적으로 작아서 학습 속도가 빠르고 메모리 소모량이 매우 낮다는 장점이 있다.
    
    반복적인 학습을 통해 기울기를 보정해가면서 오차를 보정한다.
    
    수학적으로 보면 기울기를 뽑아내기 위한 미분에 해당하는 알고리즘이다.
    
    다만 시각화를 통해 학습을 살펴보면 다음과 같이 불안정하게 움직이는데 이는 하나의 샘플 데이터를 추출 할 때 무작위로 추출하기 때문이다.
     그리고 무작위성을 갖고 있기 때문에  지역 최솟값에서 빠져나오기는 쉬우나 전역 최솟값에 다다르기에는 어렵다.
    
    ![Untitled](/images/Stochastic_R/Untitled.png)
    

- 왜 중요한가?
    
     머신 러닝의 궁극적인 목표는 오차를 줄여 정확도를 높이는 것인데 이 SGDClassifier이 오차를 줄이는데 유용하기 때문이다.
     그리고 SGDClassifier에 해당하는 알고리즘의 예로는 딥러닝(이미지, 텍스트), 트리 알고리즘 + 경사 하강법 알고리즘 = 부스팅 계열의 알고리즘이 있는데
    이 중 부스팅 계열에 해당하는 알고리즘에는 LightGBM, Xgboost, Catboost가 현장에서 많이 쓰이는 알고리즘 있기 때문이다. 참고로 이들의 하이퍼파라미터는 80개가 넘는다.
    

참조 : [https://gooopy.tistory.com/69](https://gooopy.tistory.com/69)